# MainCrafts AI_ML Task 3
# Model Validation and Hyperparameter Optimization in Machine Learning

## Project Overview
This project focuses on evaluating machine learning models and improving their performance using proper validation techniques. The main objective is to understand overfitting, apply cross-validation, and use hyperparameter tuning to build a model that generalizes well on unseen data.

The project demonstrates how a baseline model can be improved by controlling overfitting and selecting optimal hyperparameters using GridSearchCV.


## Objectives
- Understand overfitting and underfitting in machine learning models  
- Perform train-test split for initial evaluation  
- Apply cross-validation for reliable performance measurement  
- Tune model hyperparameters using GridSearchCV  
- Evaluate models using RMSE and R² metrics  
- Compare baseline and tuned models  


## Concepts Covered
- Train-Test Split  
- Overfitting vs Underfitting  
- Cross-Validation (K-Fold)  
- Hyperparameter Tuning  
- GridSearchCV  
- RMSE and R² evaluation metrics  


## Technologies Used
- Python  
- NumPy  
- Pandas  
- Matplotlib  
- scikit-learn  


## Dataset
- **California Housing Dataset**
- Source: `sklearn.datasets`
- This dataset contains housing-related features used to predict house prices.


## Models Implemented
- Linear Regression (Baseline Model)  
- Decision Tree Regressor (Untuned)  
- Decision Tree Regressor (Tuned using GridSearchCV)  


## Model Evaluation Metrics
- **RMSE (Root Mean Squared Error)** – Measures prediction error magnitude  
- **R² Score** – Measures how well the model explains variance in data  


## Project Structure
Task-3
-  AI_ML_Task3_Model Validation and Hyperparameter Optimization in Machine Learning.ipynb
-  AI_ML_Task3_Model Validation and Hyperparameter Optimization in Machine Learning report.pdf
-  README.md


## Key Outcomes
- Identified overfitting in complex models  
- Improved model performance using cross-validation  
- Reduced error using hyperparameter tuning  
- Selected the best model based on evaluation metrics  


## Conclusion
The project shows that proper model validation and tuning are essential for building reliable machine learning models. Cross-validation and GridSearchCV significantly help in improving model generalization and avoiding overfitting.
